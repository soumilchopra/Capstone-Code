{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a8c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import scipy  \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import wfdb\n",
    "import ast\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3e8305-c7e2-4ed0-a998-b0836517a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dfHeaders, path):\n",
    "    data = [wfdb.rdsamp(path+f) for f in dfHeaders['filename_lr']]\n",
    "    data = torch.Tensor(np.array([signal for signal, meta in data]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def getLabel(codeDict, SCP): \n",
    "    diag = []  \n",
    "    for key in codeDict.keys():\n",
    "        if key in SCP.index: \n",
    "            diag.append(SCP.loc[key]['diagnostic_class'])\n",
    "    diag = np.asarray(list(set(diag)))              \n",
    "    return diag\n",
    "\n",
    "\n",
    "def getOHE(header):\n",
    "    mlb = MultiLabelBinarizer()           \n",
    "    ohe = pd.DataFrame(mlb.fit_transform(header['scp_codes']), columns = mlb.classes_, index=header['scp_codes'].index)  \n",
    "    return ohe\n",
    "\n",
    "\n",
    "def get3LSignal(data, header):\n",
    "    combData = []\n",
    "    for d in data:\n",
    "        d = d.T\n",
    "        combSig = (d[0,:]+d[1,:]+d[2,:])/3\n",
    "        combData.append(combSig.tolist())\n",
    "    return pd.DataFrame(combData, index=header.index.to_numpy())\n",
    "\n",
    "\n",
    "def getDataLoader(X_train, X_test, Y_train, Y_test, batch_size):\n",
    "    trainLoad = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "    testLoad = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    trainLoad = torch.utils.data.DataLoader(trainLoad, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "    testLoad = torch.utils.data.DataLoader(testLoad, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "    return trainLoad, testLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee428acf-0783-46b6-8cf6-dfa4ac437ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHeaders = pd.read_csv('ptb-xl/ptbxl_database.csv', index_col = 'ecg_id').dropna(axis=1)\n",
    "dfHeaders['scp_codes'] = dfHeaders['scp_codes'].apply(lambda x: ast.literal_eval(x))\n",
    "dfSCP = pd.read_csv('ptb-xl/scp_statements.csv', index_col=0)\n",
    "dfSCP = dfSCP[dfSCP['diagnostic']==1]\n",
    "output_size = 5 \n",
    "\n",
    "data = get3LSignal(loadData(dfHeaders, 'ptb-xl/'), dfHeaders)\n",
    "dfHeaders['scp_codes'] = dfHeaders['scp_codes'].apply(lambda x: getLabel(x, dfSCP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4bf227-2798-4c08-a498-5a583418afc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13245000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use OHE for binary, tempOHE for multi-label binary\n",
    "tempOHE, OHE = getOHE(dfHeaders), getOHE(dfHeaders)['NORM']\n",
    "output_size = 1\n",
    "dataWLabel = pd.merge(tempOHE, data, how='outer', left_index=True, right_index=True)\n",
    "cdData = dataWLabel.groupby(by=['CD'], axis=0).mean().iloc[1,4:]\n",
    "hypData = dataWLabel.groupby(by=['HYP'], axis=0).mean().iloc[1,4:]\n",
    "miData = dataWLabel.groupby(by=['MI'], axis=0).mean().iloc[1,4:]\n",
    "normData = dataWLabel.groupby(by=['NORM'], axis=0).mean().iloc[1,4:]\n",
    "sttcData = dataWLabel.groupby(by=['STTC'], axis=0).mean().iloc[1,4:]\n",
    "\n",
    "# CD and MI look most like normData\n",
    "truncID = tempOHE[tempOHE['CD']==1].index.to_numpy()\n",
    "truncID = np.append(truncID, tempOHE[tempOHE['MI']==1].index.to_numpy())\n",
    "truncData = data[~data.index.isin(truncID)]\n",
    "OHE = OHE[~OHE.index.isin(truncID)]\n",
    "data = truncData\n",
    "display(OHE.size)\n",
    "display(truncData.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae2e9af-07a4-41c7-a8e6-c830c90bb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainID = dfHeaders[dfHeaders['strat_fold']<10].index.to_numpy()\n",
    "testID = dfHeaders[dfHeaders['strat_fold']==10].index.to_numpy()\n",
    "X_train, Y_train = data[data.index.isin(trainID)], OHE[OHE.index.isin(trainID)]\n",
    "X_test, Y_test = data[~data.index.isin(trainID)], OHE[~OHE.index.isin(trainID)]\n",
    "X_train = torch.Tensor(X_train.to_numpy()).unsqueeze(dim=2).float()\n",
    "X_test = torch.Tensor(X_test.to_numpy()).unsqueeze(dim=2).float()\n",
    "Y_train = torch.Tensor(Y_train.to_numpy()).float()\n",
    "Y_test = torch.Tensor(Y_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fafce176-5cdf-4182-95db-69b56a223d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getAcc(true, pred):\n",
    "    if true.dim() != 1:\n",
    "        return sklearn.metrics.balanced_accuracy_score(true[:,3], pred[:,3])*100\n",
    "    return sklearn.metrics.balanced_accuracy_score(true, pred)*100\n",
    "\n",
    "\n",
    "def analyzeList(labelList, predList, output_size, loss_eq, threshold=.5): \n",
    "    pred = torch.Tensor(np.where(np.asarray(predList) > threshold, 1, 0)).view(-1,output_size).squeeze()\n",
    "    true = torch.Tensor(np.asarray(labelList)).view(-1,output_size).squeeze()\n",
    "    \n",
    "    acc = getAcc(true, pred)\n",
    "    avg_loss = loss_eq(torch.Tensor(predList), torch.Tensor(labelList)).item()\n",
    "    return acc, avg_loss, true, pred\n",
    "\n",
    "\n",
    "def getGraph(trainloss, true, pred):\n",
    "    plt.title(\"Training Avg Loss\")\n",
    "    plt.plot(trainloss)\n",
    "    plt.show()\n",
    "    plt.title(\"Derivative of Avg training Loss\")\n",
    "    plt.plot(np.diff(np.diff(trainloss)))\n",
    "    plt.show()\n",
    "    if true.dim() != 1: \n",
    "        true = true[:,3]\n",
    "        pred = pred[:,3]\n",
    "    print(\"AUC: \" + str(sklearn.metrics.roc_auc_score(y_true=true, y_score=pred)))\n",
    "    plt.title(\"ROC\")\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true=true, y_score=pred)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4482971-fe98-4f06-be2e-f91a15b09178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(testLoad, model, loss_eq, batch_size):\n",
    "    predList, labelList = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (feature, label) in enumerate(testLoad):    \n",
    "            hn, cn = model.initHid(batch_size), model.initHid(batch_size)\n",
    "            pred, hn, cn = model(feature, hn, cn)\n",
    "            pred = pred.squeeze().numpy().tolist()\n",
    "            label = label.squeeze().numpy().tolist()\n",
    "            if type(pred)!=list:\n",
    "                predList.extend([pred])\n",
    "                labelList.extend([label])\n",
    "            else:\n",
    "                predList.extend(pred)\n",
    "                labelList.extend(label)       \n",
    "                \n",
    "    return labelList, predList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b67cd8a-36a5-4765-b0fc-5771478837cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def paramOptim(trainLoad, testLoad, params, epochs, output_size=1):\n",
    "    start_time = time.time()\n",
    "    hidden_size = params[0]\n",
    "    num_layers = params[1]\n",
    "    lr = params[2]\n",
    "    batch_size = params[3]\n",
    "    input_size = 1\n",
    "    drop = .1\n",
    "    \n",
    "    RNNModel = RNN(input_size, hidden_size, num_layers, output_size, drop, bidi=False)    \n",
    "    loss_eq = nn.MSELoss(reduction='mean') \n",
    "    trainloss = trainLoop(RNNModel, trainLoad, epochs, batch_size, loss_eq, lr)\n",
    "    testLL, testPL = test(testLoad, RNNModel, loss_eq, batch_size)\n",
    "    testacc, testloss, true, pred = analyzeList(testLL, testPL, output_size, loss_eq, .5)\n",
    "    \n",
    "    print(\"Testing Acc: \" + str(testacc))\n",
    "    print(\"Testing Loss: \" + str(testloss))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return trainloss, true, pred, RNNModel\n",
    "\n",
    "\n",
    "def trainLoop(model, trainLoad, epochs, batch_size, loss_eq, lr):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = .9)\n",
    "    trainloss = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print(\"Epoch: \" + str(i+1))\n",
    "        tnloss = train(trainLoad, model, loss_eq, optimizer, batch_size)\n",
    "        trainloss.append(tnloss)\n",
    "    return trainloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b27eab-d386-48f1-9d15-0b5db981ff52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(trainLoad, model, loss_eq, optimizer, batch_size): \n",
    "    tnlossList = []\n",
    "    for i, (feature, label) in enumerate(trainLoad):   \n",
    "        optimizer.zero_grad()\n",
    "   \n",
    "        hn, cn = model.initHid(batch_size), model.initHid(batch_size)        \n",
    "        pred, hn, cn = model(feature, hn, cn)\n",
    "        \n",
    "        loss = loss_eq(pred.squeeze(), label.squeeze())\n",
    "        tnlossList.append(loss.item())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    return sum(tnlossList)/len(tnlossList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72e9126e-1788-49d9-9957-3b45c924fcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, drop, bidi):\n",
    "        super(RNN, self).__init__() \n",
    "        self.hidden_size = hidden_size \n",
    "        self.num_layers = num_layers \n",
    "        self.bidi = int(bidi)\n",
    "        self.LSTM = nn.LSTM(input_size, hidden_size, num_layers, bias=True, batch_first=True, bidirectional=bidi)\n",
    "        self.fc = nn.Sequential(nn.Linear((self.bidi+1)*hidden_size, 1, bias=False),\n",
    "                                nn.Sigmoid())\n",
    "                                \n",
    "            \n",
    "    def forward(self, feature, hn, cn): \n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        out, (hn, cn) = self.LSTM(feature, (hn, cn))\n",
    "\n",
    "        if self.bidi: \n",
    "            cat = torch.cat((hn[-2, :, :], hn[-1, :, :]), dim=1)#should be (batch, 2*nodes)\n",
    "        else:\n",
    "            cat = out[:,-1,:] # should be (batch, nodes)\n",
    "            \n",
    "        out = self.fc(cat)\n",
    "        return out, hn, cn\n",
    "\n",
    "    \n",
    "    def initHid(self, batch_size):\n",
    "        hn = torch.zeros((self.bidi+1)*self.num_layers, batch_size, self.hidden_size).float()\n",
    "        return hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93bb812-2cb3-4747-b7ee-ce4fcbf7f302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 2, 0.05, 128]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# params = [nodes, layers, loss rate, batch size]\n",
    "paramDict = {\n",
    "    'T': [20, 2, .05, 128],\n",
    "    #'C': [50, 3,  512]\n",
    "} \n",
    "for key in paramDict:\n",
    "    params = paramDict[key]\n",
    "    display(params)\n",
    "    trainLoad, testLoad = getDataLoader(X_train, X_test, Y_train, Y_test, batch_size=params[3])\n",
    "    trainloss, true, pred, model = paramOptim(trainLoad, testLoad, params, epochs=20, output_size=output_size)\n",
    "    display(true.sum())\n",
    "    display(pred.sum())\n",
    "    display(len(pred))\n",
    "    getGraph(trainloss, true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99198a6-f8e0-481a-a0be-b1d99015da22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Real Data\n",
    "df_real = pd.read_csv('unlabeled.csv', dtype=np.float64, header=None, skiprows=1)\n",
    "df_ecg = df_real[1]\n",
    "\n",
    "df_ecg = pd.Series((df_ecg-df_ecg.min())/(df_ecg.max()-df_ecg.min()))\n",
    "idx0 = df_ecg[0:100].idxmax()\n",
    "df_chop = df_ecg[idx0:idx0+187].reset_index(drop=True)\n",
    "real_data = torch.Tensor(df_chop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cc97d-0293-4c30-b7c4-f0ddff5e90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testReal(sample, model):\n",
    "    with torch.no_grad():\n",
    "        hn, cn = model.initHid(batch_size=params[3]), model.initHid(batch_size=params[3])\n",
    "        pred, hn, cn = model(sample, hn, cn)\n",
    "        return pred\n",
    "\n",
    "sample = real_data.tile(params[3], 1).unsqueeze(dim=1)\n",
    "results = testReal(sample, model).squeeze().tolist()\n",
    "display(results)\n",
    "results = sum(results)/len(results)\n",
    "\n",
    "\n",
    "if results<.5:\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e85aa-337f-4eaf-9e45-06f78c600440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HeartHealth",
   "language": "python",
   "name": "hearthealth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
